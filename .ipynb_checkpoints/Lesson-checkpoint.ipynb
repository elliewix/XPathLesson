{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XPath Lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object of this lesson is to introduce XPath syntax and show how it is used within the LXML Python package.  XPath is a powerful query language for XML data structures.  Many systems support XPath queries, including the Oxygen XML editor and several Python packages.  This lesson will focus on how it can be used within Python, but the core XPath content should be relevant enough you to follow along using a package or tool of your choice.  There will be two distinct sections:  how to run XPath queries in Python and how XPath queries are written.  You may choose to follow along with the second section using whichever framework you are comfortable in.\n",
    "\n",
    "The scope of this lession will also be limited to just getting started and being able to run queries.  This includes, reading in a set of XML files, running XPath queries on them, and outputting the results.  XSLT or writing out XML files will not be covered, as they belong in separate lessons.\n",
    "\n",
    "## What you will need:\n",
    "\n",
    "* a set of XML files\n",
    "* a computer with Python or another platform to execute XPath queries\n",
    "* at a minimum, a working comfort of Python\n",
    "* to use Pip\n",
    "* have LXML installed for your Python instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why XPath and why not regex?\n",
    "\n",
    "As stated above, XPath is a query language for working on XML trees.  Many tutorials, usually those teasing at web scraping tasks, will show how a regular expression may be used to extract data out of XML data structures.  This is not an impossible task, depending on the situation, but using a regex in such a situation can pose a dangerous and short path.  XPath is designed to run queries on XML and as such is easier to work with for complex and unpredictable data structures.\n",
    "\n",
    "Let's dwell on this query language/data structure relationship for a moment:\n",
    "\n",
    "* Regular expressions are designed to work at the level of individual characters\n",
    "* XPath is designed to work at the level of XML elements\n",
    "* SQL is designed to work at the level of cells in database tables\n",
    "\n",
    "While it may be tempting to try and make regular expressions work on an XML file, it can be dangerous because the structure of the raw text is nearly meaningless within the perspective of XML.  Let's look at an example XML file:\n",
    "\n",
    "``` XML\n",
    "<book>\n",
    "    <author>Human, A.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\n",
    "```\n",
    "\n",
    "In this very limited example, a regular expression could easily catch the text between the `author` tag, but rarely do we have such simple XML.  Let's look at what happens when complexity is added.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = [\"\"\"<book>\n",
    "    <author>Human, A.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\n",
    "\"\"\" ,\n",
    "\n",
    "\"\"\"\n",
    "<book>\n",
    "    <author>Human, A.</author>\n",
    "    <author>Human, Another.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\n",
    "\"\"\" ,\n",
    "\n",
    "\"\"\"\n",
    "<book><author>Human, A.</author><title>This is not a book</title></book>\n",
    "\"\"\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Human, A.']\n",
      "['Human, A.', 'Human, Another.']\n",
      "['Human, A.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for t in text:\n",
    "    print re.findall(r'<author>(.+)<\\/author>', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This regex is holding strong..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book = \"\"\"\n",
    "<book>\n",
    "    <author kind = \"editor\">Human, A.</author>\n",
    "    <author kind    =  \"contributor\">Human, Another.</author>\n",
    "    <title>This is not a book</title>\n",
    "</book>\n",
    "\"\"\"\n",
    "\n",
    "re.findall(r'<author>(.+)<\\/author>', book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But regex treats all characters in the text as meaninful, when this is not true for the data structure we are working with.  Imagine writing the regex for when you're looking at multiple attributes that can appear in any order.  Sometimes there are situations where regex is just fine, but XPath should be your default choice for handling XML data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sample workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Several packages within Python have support for XPath, which is the beauty of utilizing this tool.  This tutorial will feature the LXML package.  [LXML](http://lxml.de/) has their own installation directions, which I will refer you to externally: http://lxml.de/installation.html.  However, it is supported via `pip` and `conda`.\n",
    "\n",
    "In the spirit of a Programming Historial style, let's start with just a sample workflow.\n",
    "\n",
    "Outline of this task:\n",
    "\n",
    "* read in source XML files\n",
    "* parse via LXML\n",
    "* use an XPath statement to extract some information\n",
    "* assemble and dump out that informatin\n",
    "\n",
    "More specifically, we'll be using the 2013 Digital Humanities abstracts.  These files are formatted in TEI and available at the conference website: http://dh2013.unl.edu/abstracts/.  There are two versions: an corpus of all the abstracts and the individual files.  This is not a tutorial on reading through multiple files, so this activity will be included but not expanded on.\n",
    "\n",
    "Specific tasks:\n",
    "\n",
    "* read in the TEI corpus\n",
    "* extract the ID, title, and type of each abstract\n",
    "* write out those results to a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_xml = 'DH 2013 final_xml/ab-130.xml'\n",
    "\n",
    "with open(source_xml, 'rt') as read_in:\n",
    "    raw_text = read_in.read() # read in the basic text, the file is now a string\n",
    "    \n",
    "tree = etree.fromstring(raw_text) # parse the string of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "At this point, we've read in the plain text version of our XML file and parsed that using the `etree` library from LXML.  Let's play with this for a bit.  LXML has pretty full documentation about how to use `etree` here: http://lxml.de/tutorial.html#using-xpath-to-find-text  We're going to focus on the bare bones navigation and text extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element {http://www.tei-c.org/ns/1.0}TEI at 0x1051f33f8>\n"
     ]
    }
   ],
   "source": [
    "print tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Once the file is parsed each element becomes an object we can act on.  Very roughly, we can manually inspect the file contents and know that the structure is (with `...` meaning that some code was snipped:\n",
    "\n",
    "``` XML\n",
    "<TEI>\n",
    "    <teiHeader>\n",
    "        <titleStmt>\n",
    "            <title>...</title>\n",
    "        </titleStmt>\n",
    "    ...\n",
    "    </teiHeader>\n",
    "    ...\n",
    "    <text type = '...'>\n",
    "        <body>\n",
    "        ...\n",
    "        </body>\n",
    "    </text>\n",
    "</TEI>\n",
    "```\n",
    "\n",
    "The `{http://www.tei-c.org/ns/1.0}TEI` notation is also important because it tells you that the element is being parsed as part of a namespace.  If we tried to just access `TEI` it would fail because the parser is expecting `{http://www.tei-c.org/ns/1.0}TEI` to appear.  Let's look at a basic XPath command to just extract the title text out of this individual abstract.  We need to include the namespace for TEI in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Comparative Study of Astronomical Clock towers in Europe and China based on their detailed 3D modeling']\n"
     ]
    }
   ],
   "source": [
    "print tree.xpath('//tei:title/text()', namespaces={'tei': 'http://www.tei-c.org/ns/1.0'}) # fails as we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Many times we'll have a long series of xpath statements to extract out all the information that we want, so we can store these namespace values as a variable so long as it works for all of them.  `{'tei': 'http://www.tei-c.org/ns/1.0'}` The key in this dictionary is a the name declaration.  I can name it anything in here, so long as it is unique (which is also required by virtue of this data structure being a dictionary).  The value is the URL to that schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Comparative Study of Astronomical Clock towers in Europe and China based on their detailed 3D modeling']\n"
     ]
    }
   ],
   "source": [
    "ns = {'tei': 'http://www.tei-c.org/ns/1.0'} \n",
    "\n",
    "print tree.xpath('//tei:title/text()', namespaces = ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can use XPath statements on our XML document, let's turn our attention to what is happening within the statmenet used above: `//tei:title/text()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
